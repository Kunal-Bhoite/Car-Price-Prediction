# -*- coding: utf-8 -*-
"""Code_Akarshe_Bhoite_Nanekar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14kWS74O4bIrmYxokNd0BrHktTMfQs7Zv
"""

pip install category_encoders

from pandas import  read_csv, DataFrame,Series
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn import linear_model
from plotly import graph_objs, figure_factory
from category_encoders import TargetEncoder
df=read_csv('/content/drive/MyDrive/Colab Notebooks/ML_Dataset.csv')
print(df)
print(df.info())
df['transmission'] = df['transmission'].map({'Semi-Auto': 0, 'Manual':1, 'Automatic':2, 'Other':3})
df['fuelType'] = df['fuelType'].map({'Diesel': 0, 'Petrol':1, 'Hybrid':2, 'Other':3, 'Electric':4})
df['brand'] = df['brand'].map({'hyundi':0, 'vauxhall':1,'audi':2, 'vw':3, 'skoda':4, 'merc':5, 'toyota':6, 'bmw':7, 'ford':8})
print(df.info())
print(df.head())

cor=df.corr()
#print(cor)
f = figure_factory.create_annotated_heatmap(cor.values,list(cor.columns),list(cor.columns),cor.round(2).values,showscale=False)
f.show()

df1 = df.drop(['engineSize'], axis = 1)
print(df1.info())

X = df1.drop(['price'], axis = 1) # Features
Y = df1['price'] # Labels
print(X.shape)
print(Y.shape)

from category_encoders import TargetEncoder
Target_Encoder = TargetEncoder(cols=['model']).fit(X,Y)
X = Target_Encoder.transform(X)
print(X.info())
X.head()

X_ = StandardScaler().fit_transform(X)

cv=5
LR = linear_model.SGDRegressor(random_state = 1, penalty = None)
Hparameter_none = {'eta0': [.0001, .001, .01, .1, 1], 'max_iter':[10000, 20000, 30000, 40000]}

grid_search = GridSearchCV(estimator=LR, param_grid=Hparameter_none, scoring='r2')
grid_search.fit(X_, Y)

best_parameters = grid_search.best_params_
print("Best parameters: ", best_parameters)
best_result = grid_search.best_score_
print("Best result: ", best_result)
best_model = grid_search.best_estimator_
modified_r2 = 1-(1-best_result)*(4/5*r-1)/(4/5*r-c-1)
print("modified_r2: ", modified_r2)
print("Intercept β0: ", best_model.intercept_)
print(DataFrame(zip(X.columns, best_model.coef_), columns=['Features','Coefficients']).sort_values(by=['Coefficients'],ascending=False))



cv=5
LR1 = linear_model.SGDRegressor(random_state = 1, penalty = 'elasticnet')
Hparameter1 = {'eta0': [.0001, .001, .01, .1, 1], 'max_iter':[10000, 20000, 30000, 40000],'alpha': [.001, .01, .1, 1,10, 100], 'l1_ratio': [0,0.25,0.5,0.75,1]}

grid_search1 = GridSearchCV(estimator=LR1, param_grid=Hparameter1, scoring='r2')
grid_search1.fit(X_, Y)

best_parameters = grid_search1.best_params_
print("Best parameters: ", best_parameters)
best_result = grid_search1.best_score_
print("Best result: ", best_result)
best_model = grid_search1.best_estimator_
modified_r2 = 1-(1-best_result)*(4/5*r-1)/(4/5*r-c-1)
print("modified_r2: ", modified_r2)
print("Intercept β0: ", best_model.intercept_)
print(DataFrame(zip(X.columns, best_model.coef_), columns=['Features','Coefficients']).sort_values(by=['Coefficients'],ascending=False))

cv=5
LR2 = linear_model.SGDRegressor(random_state = 1, penalty = 'l1')
Hparameter2 = {'eta0': [.0001, .001, .01, .1, 1], 'max_iter':[10000, 20000, 30000, 40000],'alpha': [.001, .01, .1, 1,10, 100], 'l1_ratio': [0,0.25,0.5,0.75,1]}

grid_search2 = GridSearchCV(estimator=LR2, param_grid=Hparameter2, scoring='r2')
grid_search2.fit(X_, Y)


best_parameters = grid_search2.best_params_
print("Best parameters: ", best_parameters)
best_result = grid_search2.best_score_
print("Best result: ", best_result)
best_model = grid_search.best_estimator_
modified_r2 = 1-(1-best_result)*(4/5*r-1)/(4/5*r-c-1)
print("modified_r2: ", modified_r2)
print("Intercept β0: ", best_model.intercept_)
print(DataFrame(zip(X.columns, best_model.coef_), columns=['Features','Coefficients']).sort_values(by=['Coefficients'],ascending=False))

LR3 = linear_model.SGDRegressor(random_state = 1, penalty = 'l2')
Hparameter3 = {'eta0': [.0001, .001, .01, .1, 1], 'max_iter':[10000, 20000, 30000, 40000],'alpha': [.001, .01, .1, 1,10, 100], 'l1_ratio': [0,0.25,0.5,0.75,1]}

grid_search3 = GridSearchCV(estimator=LR3, param_grid=Hparameter3, scoring='r2', cv=5)
grid_search3.fit(X_, Y)


best_parameters = grid_search3.best_params_
print("Best parameters: ", best_parameters)
best_result = grid_search3.best_score_
print("Best result: ", best_result)
best_model = grid_search.best_estimator_
modified_r2 = 1-(1-best_result)*(4/5*r-1)/(4/5*r-c-1)
print("modified_r2: ", modified_r2)
print("Intercept β0: ", best_model.intercept_)
print(DataFrame(zip(X.columns, best_model.coef_), columns=['Features','Coefficients']).sort_values(by=['Coefficients'],ascending=False))

from sklearn.svm import SVR
cv=5
SVRegressor = SVR()
Hparameters = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [100,1000,10000]}
grid_search4 = GridSearchCV(estimator=SVRegressor, param_grid=Hparameters, scoring='r2')
grid_search4.fit(X_, Y)

best_parameters = grid_search4.best_params_
print("Best parameters: ", best_parameters)
best_result = grid_search4.best_score_
print("Best result: ", best_result)
modified_r2 = 1-(1-best_result)*(4/5*r-1)/(4/5*r-c-1)
print("modified_r2: ", modified_r2)

from sklearn.ensemble import RandomForestRegressor
cv=5
RF_Regressor1 = RandomForestRegressor(criterion='squared_error', max_features='sqrt', random_state=1)
no_Trees = {'n_estimators': [10,20,30,40,50,100]}
grid_search4 = GridSearchCV(estimator=RF_Regressor1, param_grid=no_Trees, scoring='r2')
grid_search4.fit(X_, Y)

best_parameters = grid_search4.best_params_
print("Best parameters: ", best_parameters)
best_result = grid_search4.best_score_
print("best_score: ", best_result)
modified_r2 = 1-(1-best_result)*(4/5*r-1)/(4/5*r-c-1)
print("modified_r2: ", modified_r2)
Important_feature = Series(grid_search4.best_estimator_.feature_importances_, index=list(X)).sort_values(ascending=False) # Getting feature importances list for the best model
print(Important_feature)